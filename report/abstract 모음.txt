기계 학습 알고리즘이 세상에 등장하고 많은 시간이 지나면서 해석가능성과 공정성은 각자의 영역에서 발전해 왔다. 하지만 두 영역의 결합에 대한 연구는 걸음마 단계여서 해석 가능하면서 공정한 분류 모형은 많지 않다. 예시로 성능이 좋다고 잘 알려진 LightGBM 기반인 FairGBM은 성능이 좋을 뿐만 아니라 공정성까지 추구한다. 그러나 설명가능성이 없으므로 모델은 우리가 해결하고자 하는 문제의 핵심과 무관한 부분을 집중적으로 관찰하여 예측할 수도 있다. 여기서 영감을 받아 설명가능한 ANOVA Boosting 방법론에 fair loss를 추가하여 우리는 Fair ANOVA Boosting을 제안한다. 우리 방법론은 fairness를 위한 feature가 무엇인지 얻을 수 있으므로 다양한 상황에서 효용을 가져올 수 있다.

As machine learning algorithms emerged in the world and many years passed, interpretability and fairness have developed in their respective areas. However, the study of the combination of the two areas is in its infancy, so there are not many interpretable and fair classification models. For example, FairGBM, a well-known LightGBM-based boosting model, not only pursues good performance but also fairness. However, since it is not interpretable, the model can also perform a prediction by observing intensively areas unrelated to the core of the problem we are trying to solve. Inspired here, we propose Fair ANOVA Boosting by adding fair loss to the interpretable ANOVA Boosting algorithm. Fair ANOVA Boosting can obtain what feature is for fairness, so it can bring utility and reliability in various situations.

Abstract
Pre-trained representations are becoming crucial for many NLP and perception tasks. While representation learning in NLP has transitioned to training on raw text without human annotations, visual and vision-language representations still rely heavily on curated training datasets that are expensive or require expert knowledge. For vision applications, representations are mostly learned using datasets with explicit class labels such as ImageNet or OpenImages. For vision-language, popular datasets like Conceptual Captions, MSCOCO, or CLIP all involve a non-trivial data collection (and cleaning) process. This costly curation process limits the size of datasets and hence hinders the scaling of trained models. In this paper, we leverage a noisy dataset of over one billion image alt-text pairs, obtained without expensive filtering or post-processing steps in the Conceptual Captions dataset. A simple dual-encoder architecture learns to align visual and language representations of the image and text pairs using a contrastive loss. We show that the scale of our corpus can make up for its noise and leads to state-of-the-art representations even with such a simple learning scheme. Our visual representation achieves strong performance when transferred to classification tasks such as ImageNet and VTAB. The aligned visual and language representations enables zero-shot image classification and also set new state-of-the-art results on Flickr30K and MSCOCO image-text retrieval benchmarks, even when compared with more sophisticated cross-attention models. The representations also enable cross-modality search with complex text and text + image queries.

사전 훈련된 표현은 많은 NLP 및 인식 작업에서 중요해지고 있다. NLP의 표현 학습은 인간 주석이 없는 원시 텍스트에 대한 훈련으로 전환되었지만 시각적 및 비전 언어 표현은 여전히 비용이 많이 들거나 전문적인 지식이 필요한 훈련된 데이터 세트에 크게 의존한다. 비전 애플리케이션의 경우 표현은 대부분 ImageNet 또는 OpenImages와 같은 명시적 클래스 레이블이 있는 데이터 세트를 사용하여 학습된다. 비전 언어의 경우 개념 캡션, MSCOCO 또는 CLIP과 같은 인기 있는 데이터 세트에는 모두 사소한 데이터 수집(및 청소) 프로세스가 포함된다. 이 비용이 많이 드는 큐레이션 프로세스는 데이터 세트의 크기를 제한하므로 훈련된 모델의 확장을 방해한다. 본 논문에서는 개념 캡션 데이터 세트에서 값비싼 필터링 또는 후 처리 단계 없이 얻은 10억 개 이상의 이미지 alt-text 쌍으로 구성된 노이즈가 많은 데이터 세트를 활용한다. 간단한 이중 인코더 아키텍처는 대조적인 손실을 사용하여 이미지와 텍스트 쌍의 시각적 및 언어 표현을 정렬하는 방법을 학습한다. 우리는 말뭉치의 규모가 그러한 간단한 학습 계획으로도 노이즈를 보완하고 최첨단 표현으로 이어질 수 있음을 보여준다. 우리의 시각적 표현은 ImageNet 및 VTAB와 같은 분류 작업으로 전송될 때 강력한 성능을 달성한다. 정렬된 시각적 및 언어 표현은 제로샷 이미지 분류를 가능하게 하고 더 정교한 교차 주의 모델과 비교하더라도 Flickr30K 및 MSCOCO 이미지 텍스트 검색 벤치마크에서 새로운 최첨단 결과를 설정한다. 또한 표현은 복잡한 텍스트 및 텍스트 + 이미지 쿼리를 사용한 교차 양식 검색을 가능하게 한다.

Abstract
Heart disease, one of the main reasons behind the high mortality rate around the world, requires a sophisticated and expensive diagnosis process. In the recent past, much literature has demonstrated machine learning approaches as an opportunity to efficiently diagnose heart disease patients. However, challenges associated with datasets such as missing data, inconsistent data, and mixed data (containing inconsistent missing data both as numerical and categorical) are often obstacles in medical diagnosis. This inconsistency led to a higher probability of misprediction and a misled result. Data preprocessing steps like feature reduction, data conversion, and data scaling are employed to form a standard dataset—such measures play a crucial role in reducing inaccuracy in final prediction. This paper aims to evaluate eleven machine learning (ML) algorithms—Logistic Regression (LR), Linear Discriminant Analysis (LDA), K-Nearest Neighbors (KNN), Classification and Regression Trees (CART), Naive Bayes (NB), Support Vector Machine (SVM), XGBoost (XGB), Random Forest Classifier (RF), Gradient Boost (GB), AdaBoost (AB), Extra Tree Classifier (ET)—and six different data scaling methods—Normalization (NR), Standscale (SS), MinMax (MM), MaxAbs (MA), Robust Scaler (RS), and Quantile Transformer (QT) on a dataset comprising of information of patients with heart disease. The result shows that CART, along with RS or QT, outperforms all other ML algorithms with 100% accuracy, 100% precision, 99% recall, and 100% F1 score. The study outcomes demonstrate that the model’s performance varies depending on the data scaling method.

전 세계적으로 높은 사망률의 주요 원인 중 하나인 심장병은 복잡하고 비용이 많이 드는 진단 과정이 필요하다. 최근 많은 문헌이 심장병 환자를 효율적으로 진단할 수 있는 기회로 머신 러닝 접근법을 입증했다. 그러나 누락된 데이터, 일관성 없는 데이터 및 혼합 데이터(수치 및 범주형 모두로 일관성 없는 누락된 데이터를 포함)와 같은 데이터 세트와 관련된 문제는 종종 의료 진단의 장애물이다. 이러한 불일치는 더 높은 예측 확률과 잘못된 결과로 이어졌다. 기능 축소, 데이터 변환 및 데이터 확장과 같은 데이터 전처리 단계가 표준 데이터 세트를 형성하기 위해 사용된다. 이러한 조치는 최종 예측의 부정확성을 줄이는 데 중요한 역할을 한다. 이 논문은 로지스틱 회귀 분석(LR), 선형 판별 분석(LDA), KNN(K-Nearest Neighbors), 분류 및 회귀 트리(CART), Nabe Bayes(NB), 지원 벡터 머신(SVM), XGBoost(XGB), 랜덤 포레스트 분류기(RForestifier), 추가 트리(RFABoost), 추가 트리(Boost) 등 11가지 알고리듬을 평가하는 것을 목표로 한다.IE(ET)—및 6가지 데이터 스케일링 방법—심장질환 환자의 정보로 구성된 데이터 세트에서 정규화(NR), 스탠드스케일(SS), MinMax(MM), MaxAbs(MA), Robust Scaler(RS), Quantile Transformer(QT) 등. 결과는 CART가 RS 또는 QT와 함께 100% 정확도, 100% 정밀도, 99% 리콜 및 100% F1 점수로 다른 모든 ML 알고리듬을 능가한다는 것을 보여준다. 연구 결과는 모델의 성능이 데이터 확장 방법에 따라 다르다는 것을 보여줍니다.
