causal inference의 실험 데이터 study에서는 treatment와 control이 불균형하고 제어할 수 없는 경우가 많다. 이러한 경우는 성향 점수를 부여하여 데이터 불균형을 해소한다. 성항 점수 추정을 통해 ATE를 추정하는 과정에서 우리는 Improving Propensity Score Weighting Using Machine Learning 논문의 영감을 받아 머신러닝으로 강화된 기법을 사용한다. 이 방법은 propensity score weighting 을 실제 데이터에서 효용이 강한 방향으로 강화했다.

 이 논문에서는  7가지 시나리오의 데이터를 만들어서 시뮬레이션을 돌렸는데, 가장 이상적인 addictivity와 linearity 가정이 성립되는 데이터부터 가장 실제 데이터와 유사한 non-linearity, non-addicitivity dataset까지 점점 확장하여 실험한다. 가장 이상적인 dataset에서는 propensity 추정시에 모든 모델에서 evaluation이 잘 나오지만 가장 실제와 가까운 모델에서는 logistic regression 보다 random forest나 강화된 cart(pruned-cart, bagged-cart, boosted-cart)에서 성능이 잘 나왔다. 우린 이걸 시뮬레이션 데이터가 아닌 실제 데이터에 적용해서 performance가 잘 나오는지 확인해볼 것이다. 먼저 causal inference에서 유명하고 잘 정제된 dataset chemical에서 시작하여 정제되지 않은 국민영양건강조사 dataset, ㅇㅇ dataset으로 확장한다. 퍼포먼스 메트릭은 이 논문과 같이 covariate balance, standard error, per cent absolute bias, and 95 per cent confidence interval (CI) coverage 로 이용하여 논문의 주장을 확인하는 것을 목표로 한다.


Treatment and control are often unbalanced and uncontrollable in the observational study of the causal interface. In this case, a propensity score can be given to resolve the data imbalance. In the process of estimating Average Treatment Effect(ATE) by estimating propensity score, we use a machine learning-enhanced technique inspired by the Improving Propensity Score Weighting Using Machine Learning paper. This method enhances the propensity score weighting in a way that is highly useful in real data.
 In this paper, they create data from seven scenarios and run simulations, and experiment with increasing extensions from the data where the ideal additivity and linearity assumptions are established to the non-linearity and non-additivity datasets similar to the real data. In the most ideal dataset, evaluation is better in all models when estimating propensity, but in the most realistic datasets, performance is better in Random Forest or reinforced CART (pruned-CART, bagged-CART, boosted-CART) than logistic regression. We will apply this models to real data, not simulation data, to see if performance is really good in real data. 
 First, we starts with a famous and well-refined datasets, Chemical and expands to an unrefined datasets, such as national nutrition health survey dataset and oo dataset. We aims to verify the arguments of this paper using same performance metrics which are covariate balance, standard error, percent absolute bias, and 95 percent confidence interval (CI) coverage as shown in this paper.